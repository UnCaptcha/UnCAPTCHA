{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 17:12:13.264817: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from preprocess import get_data_ocr\n",
    "from sklearn import preprocessing\n",
    "from ocr import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, X_val, Y_train, Y_test, Y_val = get_data_ocr(.3, \"./../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_encoder = preprocessing.LabelEncoder().fit(np.concatenate((Y_train.reshape(-1), Y_test.reshape(-1), Y_val.reshape(-1))))\n",
    "ohe_size = np.max(char_encoder.transform(np.concatenate((Y_train.reshape(-1), Y_test.reshape(-1), Y_val.reshape(-1)))))\n",
    "orig_shapes = [Y_train.shape[0], Y_test.shape[0], Y_val.shape[0]]\n",
    "Y_train = char_encoder.transform(Y_train.reshape(-1)).reshape((orig_shapes[0], 4))\n",
    "Y_test = char_encoder.transform(Y_test.reshape(-1)).reshape((orig_shapes[1], 4))\n",
    "Y_val = char_encoder.transform(Y_val.reshape(-1)).reshape((orig_shapes[2], 4))\n",
    "\n",
    "#Convert input to properly shaped and typed tensors\n",
    "X_train  = tf.convert_to_tensor(np.asarray(X_train).astype(np.float32))\n",
    "Y_train  = tf.convert_to_tensor(np.asarray(Y_train))\n",
    "X_val  = tf.convert_to_tensor(np.asarray(X_val).astype(np.float32))\n",
    "Y_val  = tf.convert_to_tensor(np.asarray(Y_val))\n",
    "\n",
    "#Don't reshape test, because we need to preserve CAPTCHAs but convert to tensor\n",
    "X_test  = tf.convert_to_tensor(np.asarray(X_test).astype(np.float32))\n",
    "Y_test  = tf.convert_to_tensor(np.asarray(Y_test))\n",
    "\n",
    "#Expand Dims\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "X_val   = tf.expand_dims(X_val  , axis=-1)\n",
    "X_test  = tf.expand_dims(X_test , axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24, 72, 1)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 24, 72, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 24, 72, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 24, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 12, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 36, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 12, 36, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 12, 36, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 18, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 6, 18, 128)        73856     \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 6, 18, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 6, 18, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 3, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 6, 384)            0         \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 6, 768)           2362368   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " bidirectional_3 (Bidirectio  (None, 6, 768)           3542016   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6, 33)             25377     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,023,329\n",
      "Trainable params: 6,022,881\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape=(X_train.shape[-3], X_train.shape[-2], X_train.shape[-1])\n",
    "print(input_shape)\n",
    "\n",
    "\n",
    "def ctc(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.int32)\n",
    "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
    "\n",
    "    #input_length = tf.math.reduce_sum(y_pred, axis=-1, keepdims=False)\n",
    "    #label_length = tf.math.count_nonzero(y_true, axis=-1, keepdims=False, dtype=tf.int32)\n",
    "\n",
    "    return tf.keras.backend.ctc_batch_cost(y_true, y_pred, label_length=label_length, input_length=input_length)\n",
    "# Compile and fit model\n",
    "model = create_model(input_shape, (ohe_size+1))\n",
    "model.compile(loss=ctc,\n",
    "                optimizer=tf.keras.optimizers.Adam(.0001))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "28/28 [==============================] - 30s 841ms/step - loss: 15.1904 - val_loss: 15.0795\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 24s 845ms/step - loss: 14.6345 - val_loss: 15.3893\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 28s 993ms/step - loss: 13.5953 - val_loss: 17.7645\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 27s 987ms/step - loss: 11.8382 - val_loss: 20.4704\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 27s 964ms/step - loss: 10.0397 - val_loss: 20.0012\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 27s 982ms/step - loss: 8.5861 - val_loss: 18.3420\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 28s 1s/step - loss: 7.4738 - val_loss: 15.6496\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 27s 971ms/step - loss: 6.5056 - val_loss: 13.5687\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 27s 968ms/step - loss: 5.7871 - val_loss: 11.3339\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 26s 946ms/step - loss: 5.1264 - val_loss: 9.8319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b094d8d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=10,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, Y_val)\n",
    ")\n",
    "\n",
    "# Save model for future testing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./../models/crnn', save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 72, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 24, 72, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 24, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 36, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 36, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 12, 36, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 12, 36, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 18, 64)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 18, 128)        73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 6, 18, 128)       512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 6, 18, 128)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 6, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 6, 384)            0         \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 6, 768)           2362368   \n",
      " l)                                                              \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirectio  (None, 6, 768)           3542016   \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6, 33)             25377     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,023,329\n",
      "Trainable params: 6,022,881\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model(\"./../models/crnn\", custom_objects={'ctc': ctc})\n",
    "print(loaded_model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret CAPTCHA:\n",
      "['B' 'S' 'H' 'F']\n",
      "Model guess:\n",
      "[[1.88498339e-03 1.76497802e-01 4.24088724e-03 6.96901605e-02\n",
      "  4.57353890e-03 1.80103758e-04 3.99093449e-01 6.96475850e-03\n",
      "  5.48067596e-03 1.11697294e-01 2.75980739e-04 4.44790523e-04\n",
      "  9.24414769e-02 2.13075359e-03 7.67696090e-03 1.90014821e-02\n",
      "  5.43603637e-05 9.33453150e-04 1.83832797e-03 3.47220019e-04\n",
      "  2.45293276e-03 1.99892209e-03 4.02391015e-04 1.04253236e-02\n",
      "  1.45716369e-02 1.48199976e-03 3.71329440e-03 1.39816885e-03\n",
      "  5.41738467e-04 3.33411992e-02 1.31473318e-03 5.54270577e-03\n",
      "  1.73665229e-02]\n",
      " [7.47421349e-04 7.49142468e-02 1.36918505e-03 3.73440385e-02\n",
      "  1.99922686e-03 5.70560151e-05 2.35844001e-01 2.59431731e-03\n",
      "  4.20288043e-03 1.16405070e-01 2.08055571e-04 8.64907284e-04\n",
      "  3.09866995e-01 1.80087413e-03 1.15534933e-02 6.28343597e-02\n",
      "  2.42319529e-05 1.26413058e-03 1.61501521e-03 3.61018727e-04\n",
      "  3.34855542e-03 1.24845735e-03 6.76307769e-04 6.86017936e-03\n",
      "  9.66955628e-03 8.54055514e-04 1.08130788e-02 1.14145223e-03\n",
      "  1.02471851e-03 2.63967607e-02 6.16833509e-04 7.24032288e-03\n",
      "  6.42391890e-02]\n",
      " [2.88210227e-04 1.73378065e-02 1.92065854e-04 1.09476754e-02\n",
      "  4.54275985e-04 1.71215815e-05 4.61845323e-02 5.43073751e-04\n",
      "  2.22214311e-03 6.75791651e-02 1.24930550e-04 1.32378796e-03\n",
      "  6.03455603e-01 1.38173660e-03 7.22642709e-03 9.93534550e-02\n",
      "  1.21585153e-05 1.09816645e-03 7.03386380e-04 3.75334261e-04\n",
      "  4.13601287e-03 8.83227913e-04 8.08824960e-04 2.86914036e-03\n",
      "  3.41859995e-03 4.91310551e-04 1.75371449e-02 7.59504794e-04\n",
      "  1.78153743e-03 1.26976883e-02 2.36334512e-04 3.39851086e-03\n",
      "  9.01611000e-02]\n",
      " [1.51700646e-04 3.44417291e-03 9.55591313e-05 4.29724809e-03\n",
      "  2.22778253e-04 1.06235047e-05 6.08530454e-03 1.29163571e-04\n",
      "  9.31774499e-04 1.62980799e-02 1.36865550e-04 2.43551587e-03\n",
      "  7.47152328e-01 1.81517319e-03 5.09624649e-03 9.70783159e-02\n",
      "  1.70871845e-05 8.19563284e-04 7.37512368e-04 2.15011940e-04\n",
      "  3.35525861e-03 8.65734066e-04 6.22383202e-04 6.12827251e-04\n",
      "  8.69689567e-04 4.81551077e-04 2.94975750e-02 8.34743551e-04\n",
      "  3.41789494e-03 3.98566341e-03 1.68680650e-04 2.26253504e-03\n",
      "  6.58554584e-02]\n",
      " [2.34312305e-04 2.03217054e-03 1.57462928e-04 3.67306243e-03\n",
      "  2.76127801e-04 2.38682387e-05 3.68868862e-03 1.01890022e-04\n",
      "  1.55108364e-03 8.28812085e-03 5.42251510e-04 3.29859485e-03\n",
      "  7.79964387e-01 5.38295228e-03 5.01180580e-03 6.90519810e-02\n",
      "  8.34603852e-05 1.75365072e-03 1.90840138e-03 5.68014686e-04\n",
      "  4.65401215e-03 1.79151574e-03 7.48221471e-04 4.18905023e-04\n",
      "  7.17544928e-04 1.28979667e-03 4.78878953e-02 3.31971725e-03\n",
      "  6.81273500e-03 3.80183174e-03 3.79678444e-04 2.42848252e-03\n",
      "  3.81574109e-02]\n",
      " [4.52759065e-04 1.78751815e-03 7.98019872e-04 3.63964704e-03\n",
      "  5.67021489e-04 1.22056284e-04 2.69179838e-03 1.36841205e-04\n",
      "  4.36379015e-03 4.03333921e-03 3.75208911e-03 4.47930023e-03\n",
      "  7.45846987e-01 3.40454951e-02 6.82485569e-03 3.98114733e-02\n",
      "  1.37505308e-03 6.32945355e-03 1.36058489e-02 9.74885712e-04\n",
      "  8.31664447e-03 4.43268055e-03 9.75392060e-04 5.81352448e-04\n",
      "  1.04681775e-03 6.68847747e-03 6.33024722e-02 1.39020933e-02\n",
      "  8.15066230e-03 4.30099573e-03 1.37263187e-03 3.63654015e-03\n",
      "  7.65507109e-03]]\n",
      "[ 6 12 12 12 12 12]\n",
      "UniqueWithCounts(y=<tf.Tensor: shape=(2,), dtype=int64, numpy=array([ 6, 12])>, idx=<tf.Tensor: shape=(6,), dtype=int32, numpy=array([0, 1, 1, 1, 1, 1], dtype=int32)>, count=<tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 5], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run random CAPTCHA test\n",
    "output = model.predict(X_test[1:2], verbose=0)\n",
    "print(\"Secret CAPTCHA:\")\n",
    "print(char_encoder.inverse_transform(Y_test[1]))\n",
    "print(\"Model guess:\")\n",
    "output = np.transpose(output, axes=[1, 0, 2]).squeeze()\n",
    "print(output)\n",
    "print(np.argmax(output, axis=1))\n",
    "# _, max_index = np.max(output, axis=2)\n",
    "#raw_prediction = list(max_index[:, i].detach().cpu().numpy())\n",
    "prediction = tf.unique_with_counts(np.argmax(output, axis=1))\n",
    "print(prediction)\n",
    "# print(char_encoder.inverse_transform(output))\n",
    "\n",
    "# # Print individual and captcha-based accuracy\n",
    "# indiv_acc, group_acc = run_tests(model, X_test, Y_test)\n",
    "# print(f\"Individual accuracy: {round(100*indiv_acc, 2)}% \\nCaptcha accuracy: {round(100*group_acc, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OCR Accuracy\n",
    "\n",
    "def get_accuracy(model, X_test, Y_test):\n",
    "    print(X_test.shape)\n",
    "    print(Y_test.shape)\n",
    "    probs = model.predict(X_test, verbose=0)\n",
    "    output = np.argmax(probs, axis=2)\n",
    "    print(output[0:10])\n",
    "    prediction = np.asarray([np.asarray(tf.unique_with_counts(x)[0]) for x in output])\n",
    "    print(prediction[0].shape)\n",
    "    Y_test = np.asarray(Y_test)\n",
    "    count = 0\n",
    "    total = Y_test.shape[0]\n",
    "    for x, y in zip(prediction, Y_test):\n",
    "        if len(x) == len(y) and np.all(np.equal(x, y)): count += 1\n",
    "    accuracy = count / total\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1493, 24, 72, 1)\n",
      "(1493, 4)\n",
      "[[19 19 19 19 28 28]\n",
      " [19 19 19 19 19 28]\n",
      " [19 19 19 19 19  9]\n",
      " [19 19 19 19  9  9]\n",
      " [19 19 19 28 28 28]\n",
      " [19 19 19 19 28  9]\n",
      " [19 19 19 19 19 28]\n",
      " [19 19 19 19 19 28]\n",
      " [19 19 19 19 28 28]\n",
      " [19 19 19 19 19 28]]\n",
      "(2,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0x/2kts5pgd6cs9gk2hysn_90br0000gn/T/ipykernel_5482/1384438526.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  prediction = np.asarray([np.asarray(tf.unique_with_counts(x)[0]) for x in output])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./../models/ocr_basic\", custom_objects={'ctc': ctc})\n",
    "get_accuracy(model, X_test, Y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci1470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
