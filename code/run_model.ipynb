{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 16:16:36.088677: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from preprocess import get_data\n",
    "from sklearn import preprocessing\n",
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 32 is out of bounds for axis 0 with size 32",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m ohe_size \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax(char_encoder\u001b[39m.\u001b[39mtransform(np\u001b[39m.\u001b[39mconcatenate((Y_train\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), Y_test\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), Y_val\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))))\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(char_encoder\u001b[39m.\u001b[39mclasses_[\u001b[39m31\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m \u001b[39mprint\u001b[39m(char_encoder\u001b[39m.\u001b[39;49mclasses_[\u001b[39m32\u001b[39;49m])\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(char_encoder\u001b[39m.\u001b[39mclasses_[\u001b[39m20\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(char_encoder\u001b[39m.\u001b[39mclasses_[\u001b[39m5\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: index 32 is out of bounds for axis 0 with size 32"
     ]
    }
   ],
   "source": [
    "#Get data and reshape\n",
    "\n",
    "#Import and reshape\n",
    "X_train, X_test, X_val, Y_train, Y_test, Y_val = get_data(.3, \"./../processed_data/\")\n",
    "\n",
    "char_encoder = preprocessing.LabelEncoder().fit(np.concatenate((Y_train.reshape(-1), Y_test.reshape(-1), Y_val.reshape(-1))))\n",
    "ohe_size = np.max(char_encoder.transform(np.concatenate((Y_train.reshape(-1), Y_test.reshape(-1), Y_val.reshape(-1)))))\n",
    "\n",
    "orig_shapes = [Y_train.shape[0], Y_test.shape[0], Y_val.shape[0]]\n",
    "Y_train = char_encoder.transform(Y_train.reshape(-1)).reshape((orig_shapes[0], 4))\n",
    "Y_test = char_encoder.transform(Y_test.reshape(-1)).reshape((orig_shapes[1], 4))\n",
    "Y_val = char_encoder.transform(Y_val.reshape(-1)).reshape((orig_shapes[2], 4))\n",
    "\n",
    "#Convert input to properly shaped and typed tensors\n",
    "X_train = tf.convert_to_tensor(np.asarray(np.reshape(X_train, (-1, *X_train.shape[-2:]))).astype(np.float32))\n",
    "X_val   = tf.convert_to_tensor(np.asarray(np.reshape(X_val  , (-1, *X_val.shape[-2:]))).astype(np.float32))\n",
    "Y_train = tf.convert_to_tensor(np.asarray(np.reshape(Y_train, (-1))))\n",
    "Y_val   = tf.convert_to_tensor(np.asarray(np.reshape(Y_val  , (-1))))\n",
    "\n",
    "#Don't reshape test, because we need to preserve CAPTCHAs but convert to tensor\n",
    "X_test  = tf.convert_to_tensor(np.asarray(X_test).astype(np.float32))\n",
    "Y_test  = tf.convert_to_tensor(np.asarray(Y_test))\n",
    "\n",
    "#Expand Dims\n",
    "X_train = tf.expand_dims(X_train, axis=-1)\n",
    "X_val   = tf.expand_dims(X_val  , axis=-1)\n",
    "\n",
    "#One hot encode\n",
    "Y_val   = tf.one_hot(Y_val  , depth=ohe_size, axis=-1)\n",
    "Y_train = tf.one_hot(Y_train, depth=ohe_size, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Model(input_shape=(X_train.shape[-3], X_train.shape[-2], X_train.shape[-1]), num_classes=ohe_size)\n",
    "model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, (3,3), padding=\"same\", input_shape=(X_train.shape[-3], X_train.shape[-2], X_train.shape[-1])),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "            tf.keras.layers.Conv2D(64, (3,3), padding=\"same\", activation=\"leaky_relu\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "            tf.keras.layers.Conv2D(128, (3,3), padding=\"same\", activation=\"leaky_relu\"),\n",
    "            tf.keras.layers.BatchNormalization(),\n",
    "            tf.keras.layers.LeakyReLU(),\n",
    "            tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(256, activation='leaky_relu'),\n",
    "            tf.keras.layers.Dense(ohe_size)\n",
    "        ])\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                optimizer=tf.keras.optimizers.Adam(.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit and save model\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    epochs=4,\n",
    "    batch_size=256,\n",
    "    validation_data=(X_val, Y_val)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./../models/segmented_2', save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 24, 32)        320       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 24, 24, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 12, 12, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 12, 12, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 6, 6, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 6, 6, 128)        512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 6, 6, 128)         0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 3, 3, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               295168    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 31)                7967      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 396,703\n",
      "Trainable params: 396,255\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"./../models/segmented_2\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret CAPTCHA:\n",
      "['2' '5' 'M' 'Z']\n",
      "Model guess:\n",
      "['3' 'B' 'B' 'B']\n",
      "Character accuracy: 3.45% \n",
      "Captcha accuracy: 0.0%\n"
     ]
    }
   ],
   "source": [
    "#Load a model and run tests to get accuracy and print an example\n",
    "\n",
    "#TODO: I don't know how to properly load and save models, it's not working\n",
    "\n",
    "def get_acc(X_test, Y_test):\n",
    "    X_test    = np.reshape(X_test, (-1, *X_test.shape[-2:]))\n",
    "    Y_test    = np.reshape(Y_test, (-1))\n",
    "    \n",
    "    probs     = model.predict(X_test, verbose=0)\n",
    "    diff      = np.argmax(probs, axis=1) - Y_test\n",
    "    char_acc  = np.where(diff == 0, 1, 0)\n",
    "\n",
    "    captcha_acc = np.array_split(diff, diff.shape[0]//4)\n",
    "    captcha_acc = np.apply_along_axis((lambda x: 1 if np.all(x == 0) else 0), axis=1, arr=captcha_acc)\n",
    "\n",
    "    return np.mean(char_acc), np.mean(captcha_acc)\n",
    "    \n",
    "\n",
    "output = model.predict(X_test[7], verbose=0)\n",
    "\n",
    "print(\"Secret CAPTCHA:\")\n",
    "print(char_encoder.inverse_transform(Y_test[7]))\n",
    "\n",
    "print(\"Model guess:\")\n",
    "print(char_encoder.inverse_transform(np.argmax(output, axis=1)))\n",
    "\n",
    "char_acc, captcha_acc = get_acc(X_test, Y_test)\n",
    "print(f\"Character accuracy: {round(100*char_acc, 2)}% \\nCaptcha accuracy: {round(100*captcha_acc, 2)}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
