{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_path = \"./../data/raw_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess raw data into segmented images.\n",
    "def segmentation_preprocess():\n",
    "    \"\"\"\n",
    "    Cleans data and splits into character by character images\n",
    "    \"\"\"\n",
    "\n",
    "    # Cleans each image and finds contours to try to identify letters.\n",
    "    for image_name in os.listdir(data_path):\n",
    "        img_path = data_path + image_name\n",
    "        img = cv2.imread(img_path)\n",
    "        _, thresholded = cv2.threshold(img, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        to_gray = cv2.cvtColor(thresholded, cv2.COLOR_BGR2GRAY)\n",
    "        ctrs, _ = cv2.findContours(to_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        ctrs = np.asarray(ctrs, dtype=object)\n",
    "        my_rects = np.asarray([cv2.boundingRect(ctr) for ctr in ctrs])\n",
    "\n",
    "        # If less than 4 letters are identified try to manually split the largest found contour in 2.\n",
    "        while len(my_rects) != 4:\n",
    "            big_ctr_ind = np.argmax(my_rects[:, 2])\n",
    "            big_ctr = my_rects[big_ctr_ind]\n",
    "            split_width = big_ctr[2]//2\n",
    "            sub_rect_one = np.asarray([big_ctr[0], big_ctr[1], split_width, 0])\n",
    "            sub_rect_two = np.asarray([big_ctr[0] + split_width, big_ctr[1], big_ctr[2] - split_width, 0])\n",
    "            my_rects = np.concatenate((my_rects[:big_ctr_ind], np.asarray([sub_rect_one, sub_rect_two]), my_rects[big_ctr_ind + 1:]))\n",
    "        \n",
    "        # Save each of the individual characters to image.\n",
    "        my_rects = np.sort(my_rects, axis=0)\n",
    "        code = image_name.split(\".\")[0]\n",
    "        for i, rect in enumerate(my_rects):\n",
    "            new_image = to_gray[:,rect[0]-1:rect[0]+rect[2]+1] #Add one pixel of noise from original image\n",
    "            total_pad = 24 - new_image.shape[1]\n",
    "            left_pad  = total_pad // 2\n",
    "            right_pad = total_pad - left_pad\n",
    "            new_image = np.pad(new_image, pad_width=((0,0), (left_pad, right_pad)), mode=\"constant\")\n",
    "            cv2.imwrite(\"../data/segmented_data/\" + code + \"_\" + str(i) + \"_\" + code[i] + \".png\", new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to split preprocessed data into train/test/val folders.\n",
    "def get_data():\n",
    "    \"\"\"\n",
    "    Returns the data split into the proper train/test/val split.\n",
    "    \"\"\"\n",
    "    processed_data_path = \"./../data/segmented_data\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    captcha = []\n",
    "    captcha_labels = []\n",
    "    count = 0\n",
    "    # Create images and labels and in a shape such that each CAPTCHAs individual letter images are kept together\n",
    "    for image_path in sorted(os.listdir(processed_data_path)):\n",
    "        count += 1\n",
    "        image = cv2.imread(processed_data_path + image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        label = image_path.split('.')[0][-1]\n",
    "        captcha.append(image)\n",
    "        captcha_labels.append(label)\n",
    "\n",
    "        if count % 4 == 0:\n",
    "            images.append(captcha)\n",
    "            labels.append(captcha_labels)\n",
    "            captcha = []\n",
    "            captcha_labels = []\n",
    "\n",
    "    X_train, X_testval, Y_train, Y_testval = train_test_split(np.asarray(images, dtype=object), np.asarray(labels, dtype=object), test_size=.3, random_state=42)\n",
    "    X_test, X_val, Y_test, Y_val = train_test_split(X_testval, Y_testval, test_size=0.5, random_state=42)\n",
    "\n",
    "    return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "\n",
    "\n",
    "def split_it_up():\n",
    "    \"\"\"\n",
    "    Gets processed data from original folder and splits it into new folders train, test, and val\n",
    "    \"\"\"\n",
    "    save_folder = \"./../data/segmented_data_split/\"\n",
    "    X_train, X_test, X_val, Y_train, Y_test, Y_val = get_data(0.3, \"./../data/segmented_data/\")\n",
    "\n",
    "    # For each of train,test,val save the respective images to these new folders.\n",
    "    for imgs, labels in zip(X_train, Y_train):\n",
    "        for i, img in enumerate(imgs):\n",
    "            item_name = ''.join(labels) + \"_\" + str(i) + \"_\" + labels[i]\n",
    "            cv2.imwrite(save_folder + \"train/\" + item_name + '.png', np.asarray(img, dtype=np.uint8))\n",
    "\n",
    "    for imgs, labels in zip(X_test, Y_test):\n",
    "        for i, img in enumerate(imgs):\n",
    "            item_name = ''.join(labels) + \"_\" + str(i) + \"_\" + labels[i]\n",
    "            cv2.imwrite(save_folder + \"test/\" + item_name + '.png', np.asarray(img, dtype=np.uint8))\n",
    "\n",
    "    for imgs, labels in zip(X_val, Y_val):\n",
    "        for i, img in enumerate(imgs):\n",
    "            item_name = ''.join(labels) + \"_\" + str(i) + \"_\" + labels[i]\n",
    "            cv2.imwrite(save_folder + \"val/\" + item_name + '.png', np.asarray(img, dtype=np.uint8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to preprocess data and split into train/test/val folders for Segmentation & Barcoding\n",
    "segmentation_preprocess()\n",
    "split_it_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess raw data into clean images for OCR\n",
    "def ocr_preprocess():\n",
    "    \"\"\"\n",
    "    Cleans and saves data.\n",
    "    \"\"\"\n",
    "    for image_name in os.listdir(data_path):\n",
    "        img_path = data_path + image_name\n",
    "        img = cv2.imread(img_path)\n",
    "        _, thresholded = cv2.threshold(img, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        to_gray = cv2.cvtColor(thresholded, cv2.COLOR_BGR2GRAY)\n",
    "        cv2.imwrite(\"../data/ocr_data/\" + image_name, to_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to split preprocessed OCR data into train/test/val folders\n",
    "def get_data_ocr():\n",
    "    \"\"\"\n",
    "    Returns the data split into the proper train/test/val split.\n",
    "    \"\"\"\n",
    "    processed_data_path = \"./../data/ocr_data/\"\n",
    "    captcha = []\n",
    "    captcha_labels = []\n",
    "    for image_path in sorted(os.listdir(processed_data_path)):\n",
    "        image = cv2.imread(processed_data_path + image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        label = image_path.split('.')[0]\n",
    "        captcha.append(image)\n",
    "        captcha_labels.append(list(label))\n",
    "\n",
    "    X_train, X_testval, Y_train, Y_testval = train_test_split(np.asarray(captcha, dtype=object), np.asarray(captcha_labels, dtype=object), test_size=.3, random_state=42)\n",
    "    X_test, X_val, Y_test, Y_val = train_test_split(X_testval, Y_testval, test_size=0.5, random_state=42)\n",
    "\n",
    "    return X_train, X_test, X_val, Y_train, Y_test, Y_val\n",
    "\n",
    "\n",
    "def split_it_up_ocr():\n",
    "    \"\"\"\n",
    "    Gets processed data from original folder and splits it into new folders train, test, and val\n",
    "    \"\"\"\n",
    "    save_folder = \"./../data/ocr_data_split/\"\n",
    "    X_train, X_test, X_val, Y_train, Y_test, Y_val = get_data_ocr()\n",
    "    for img, label in zip(X_train, Y_train):\n",
    "        item_name = ''.join(label)\n",
    "        cv2.imwrite(save_folder + \"train/\" + item_name + '.png', np.asarray(img, dtype=np.uint8))\n",
    "\n",
    "    for img, label in zip(X_test, Y_test):\n",
    "        item_name = ''.join(label)\n",
    "        cv2.imwrite(save_folder + \"test/\" + item_name + '.png', np.asarray(img, dtype=np.uint8))\n",
    "\n",
    "    for img, label in zip(X_val, Y_val):\n",
    "        item_name = ''.join(label)\n",
    "        cv2.imwrite(save_folder + \"val/\" + item_name + '.png', np.asarray(img, dtype=np.uint8))\n",
    "\n",
    "split_it_up_ocr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to preprocess data and split into train/test/val folders for OCR.\n",
    "ocr_preprocess()\n",
    "split_it_up_ocr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
